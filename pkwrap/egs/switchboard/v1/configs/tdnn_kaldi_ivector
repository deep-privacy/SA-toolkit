[cmd]
cpu_cmd = queue.pl -l q1d -l io_big -V
cuda_cmd = queue.pl -l q_gpu -V

[exp]
# 8 layer tdnnf model. NOTE: exp/chain${chain_affix} will be prepended automatically
dirname = tdnnf8l_kaldi_ivector
train_set = data/train_nodup_sp_hires
lores_train_set = data/train_nodup_sp
gmm_dir = exp/tri4
ali_dir = exp/tri4_ali_nodup_sp
# re-use existing tree
tree_dir = exp/chain/tree_sp_train_nodup_pkwrap
tree_context_opts = "--context-width=2 --central-position=1"
lat_dir = exp/tri4_nodup_sp_lats
model_file = local/chain/tuning/model_1b.py
lang = data/lang
lang_chain = data/lang_chain
# trained from kaldi
graph_dir = exp/chain/tdnn_1h_train_nodup_sp/graph_sw1_tg

# train params
chunk_width = 140
frames_per_iter = 1200000
online_ivector_dir = exp/nnet3/ivectors_train_nodup_sp
num_epochs = 6
num_jobs_initial = 3
num_jobs_final = 14
lr_initial = 0.001
lr_final = 0.0001
diagnostics_interval = 10

[test]
test_set = data/eval2000_hires
ivector_dir = exp/nnet3/ivectors_eval2000
