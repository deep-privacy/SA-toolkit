[cmd]
cpu_cmd = ./utils/run.pl
cuda_cmd = ./utils/run.pl

[exp]
# 8 layer tdnnf model. NOTE: exp/chain${chain_affix} will be prepended automatically
e2e = True
train_set = data/train_clean_100_sp_fbank_hires
tree_dir = exp/chain/e2e_biphone_tree
# dummy folders. will not be touched
lang = data/lang_nosp_test_tgsmall
lang_chain = data/lang_chain
# trained using local/chain/e2e/prepare_data.sh and local/chain/e2e/get_egs.sh
graph_dir = exp/chain/e2e_biphone_tree/graph_tgsmall
egs_dir = exp/chain/e2e_tdnnf/fst_egs

# train params
num_epochs = 1
num_jobs_initial = 2
num_jobs_final = 5
lr_initial = 0.0005
lr_final = 0.00001
diagnostics_interval = 10
checkpoint_interval = 20
minibatch_size = 16
final_combination_n_model = 5
# train_stage = 30

model_file = local/chain/e2e/tuning/tdnnf_vq_spkdelta.py
dirname = e2e_tdnnf_vq_spkdelta_sizeco_
model_args = ["--freeze-encoder", "True", "--codebook-size", ""]
init_weight_model = "./exp/chain/e2e_tdnnf_vq_sizeco_/final.pt"

damped_args = ["--eproj", "512"]

# sed -i -E "/^dirname|^model_args|^init_weight_model/s/[0-9]{2,}/256/" configs/tdnnf_e2e_vq_spkdelta
# tail e2e_tdnnf_vq_spkdelta_sizeco_*/decode_dev*_fg/scoringDetails/best_wer

[test]
# test_set = data/test_clean_fbank_hires
# test_set = data/test_other_fbank_hires
# test_set = data/dev_other_fbank_hires
test_set = data/dev_clean_fbank_hires
# test_set = data/test_other_fbank_hires
suffix = _final2
# decode on gpus
num_jobs = 40
gpu = True

# vim:set et sw=2 ts=2 ft=toml:
