[cmd]
cpu_cmd = ./utils/run.pl
cuda_cmd = ./utils/run.pl

# Can be modified through venv: e.g.: vq=128 local/chain/train.py ...
[var]
dset = voxceleb1

[exp]
train_set = data/${:dset}
# == 0: train on full (dev -> 0.005 part of train)
dev_ratio = 0.00

test_set = data/${:dset}_test/voxceleb1-O-clean
compute_test_set_eer = true


n_gpu = 1
num_worker_dataloader = 20
logging_interval = 200
checkpoint_interval = 1

training_epochs = 10
patience = 20
minibatch_size = 128
examples_per_speaker_in_batch = "batch_size/32"
samples_per_speaker_in_epoch = 70
segment_size = 96000 # to better match test data
optim = {
  "optimizer": {
    "type": "torch.optim.AdamW",
    "opts": {"lr": 1.0e-8}
  },
  "scheduler": {
    "type": "torch.optim.lr_scheduler.ExponentialLR",
    "opts": {
      "gamma": 0.2
    }
  }
  }

# resume training from:
# train_epoch = 8
# train_epoch = last
# train_epoch = best

model_file = ./local/tuning/ecapa_tdnn.py
dirname = asv_eval_${:dset}_ecapa_tdnn_ft
model_args = ["--fine-tune", "true"]

init_weight_model = "exp/asv_eval_${:dset}_ecapa_tdnn/best.pt"

# see ../../../share/dataprep_aug.py
augmentation = {
  "pipeline": ["add_reverb", "add_noise", "phone_filtering", "codec"],
  "aug_number": 1,
  "add_noise": {
      # "babble_noise": "true",
      "noise_db_csv": "../../data/musan.csv",
      "data_path": "/"
    },
  "add_reverb": {
      "rir_db_csv": "../../data/reverb.csv",
      "data_path": "/"
    },
  "sanity_check_path" : "/tmp/sanity_test",
  "sanity_check_samples" : 2
  }

# for jit
final_model = best.pt

# vim:set et sw=2 ts=2 ft=toml:
