[cmd]
cpu_cmd = ./utils/run.pl
cuda_cmd = ./utils/run.pl

[exp]
train_set = data/train_clean_100_sp
tree_dir = exp/chain/e2e_train_clean_100/e2e_biphone_tree
egs_dir = exp/chain/e2e_train_clean_100/fst_egs

# train params
num_epochs = 4
num_jobs_initial = 1
num_jobs_final = 1
lr_initial = 5e-05
lr_final =   1e-06
diagnostics_interval = 20
checkpoint_interval =  20
# fits on a 47 GB card with wav2vec2 large
minibatch_size = 8
grad_acc_steps = 16
train_stage = last
# train_stage = 365

xent_regularize = 0.02

final_combination_n_model = 1

model_file = local/chain/e2e/tuning/tdnnf_wav2vec2.py
dirname = e2e_tdnnf_wav2vec2

[test]
graph_dir = exp/chain/e2e_train_clean_100/e2e_biphone_tree/graph_tgsmall
# test_set = data/test_clean
test_set = data/test_other
# test_set = data/dev_other
# test_set = data/dev_clean
# test_set = data/dev_clean
# suffix = baseline
# decode on gpus
num_jobs = 2
gpu = True
# iter = 428


# vim:set et sw=2 ts=2 ft=toml:
